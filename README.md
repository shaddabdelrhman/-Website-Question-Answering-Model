## **ğŸ§  Intelligent Arabic Question Answering System** 

This project implements both Generative and Extractive Arabic Question Answering (QA) systems on content scraped from the Arabic sports news website FilGoal
.
Users can ask natural-language questions in Arabic and receive accurate, context-aware answers directly derived from FilGoal articles.

# **ğŸ“˜ Project Overview**

The system processes Arabic news articles, cleans and indexes them, retrieves the most relevant passages, and then uses two different QA approaches:

- **ğŸŸ© Extractive QA** â€“ using **Arabic BERT** (asafaya/bert-base-arabic) to locate the most relevant span of text from FilGoal content that answers the question.

- **ğŸŸ¦ Generative QA** â€“ using **AraGPT2** (aubmindlab/aragpt2-base) to generate fluent, context-aware answers in natural Arabic.

Together, they form a **hybrid Arabic Question Answering framework** that combines retrieval-based accuracy with natural language fluency.

# **Implementation Steps**
**1. Data Collection** 

- **Web Scraping:** Articles were scraped from FilGoal using requests and BeautifulSoup.

- **HTML Parsing:** Extracted text from <p>, <h1â€“h6>, and <li> tags while removing scripts, ads, and irrelevant HTML.

**2. Preprocessing**

- **Text Cleaning:** Removed HTML tags, special characters, and extra spaces.

- **Chunking:** Split long articles into smaller, manageable text segments.

- **Metadata:** Stored article titles, URLs, and timestamps for better context retrieval.

**3. Retrieval**

**Techniques Used:**

- ğŸ”¹ BM25 (via rank_bm25) for keyword-based ranking.

- ğŸ”¹ FAISS for dense semantic similarity search.

Retrieves the **top-k** relevant text chunks for each user query.

**4. Answer Generation**
**ğŸŸ© Extractive Model**

- **Model:** asafaya/bert-base-arabic

- **Approach:** Identifies and extracts the most relevant text span answering the question.

**ğŸŸ¦ Generative Model**

- **Model:** aubmindlab/aragpt2-base

- **Approach:** Generates a natural Arabic answer based on the question and retrieved context.
# **Example Usage**
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("aubmindlab/aragpt2-base")
model = AutoModelForCausalLM.from_pretrained("aubmindlab/aragpt2-base")
qa_pipeline = pipeline("text-generation", model=model, tokenizer=tokenizer)

question = "Ù…Ù† ÙØ§Ø² ÙÙŠ Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù„Ø£Ù‡Ù„ÙŠ ÙˆØ§Ù„Ø²Ù…Ø§Ù„Ùƒ Ø§Ù„Ø£Ø®ÙŠØ±Ø©ØŸ"
context = "Ø§Ù„Ø£Ù‡Ù„ÙŠ ÙØ§Ø² Ø¹Ù„Ù‰ Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ Ø¨Ø«Ù„Ø§Ø«Ø© Ø£Ù‡Ø¯Ø§Ù Ù…Ù‚Ø§Ø¨Ù„ Ù‡Ø¯Ù ÙÙŠ Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ù…ØµØ±ÙŠ Ø§Ù„Ù…Ù…ØªØ§Ø²..."
response = qa_pipeline(f"Ø³Ø¤Ø§Ù„: {question}\nØ³ÙŠØ§Ù‚: {context}\nØ¥Ø¬Ø§Ø¨Ø©:", max_length=100)
print(response[0]["generated_text"])  
# **ğŸš€ Deployment**

Built as a REST API using Flask.
It accepts an Arabic question and returns either:

- **âœ… Extracted answer** (from Arabic BERT)

- **ğŸ’¬ Generated answer** (from AraGPT2)

# **ğŸ§  Future Improvements**

- Fine-tune AraGPT2 and Arabic BERT on Arabic QA datasets (e.g., Arabic-SQuAD).

- Integrate context summarization for long articles.

- Build a web interface for interactive Arabic QA.
 # **ğŸ§© Tech Stack**
**Component**	                   **Library / Tool**
**ğŸ•¸ï¸ Scraping**                    BeautifulSoup, requests
**ğŸ¤– NLP**	                       Transformers (Hugging Face), PyTorch
**ğŸ” Retrieval**	                  rank_bm25, FAISS
**ğŸ§ª Evaluation**	                evaluate, datasets
**ğŸŒ Deployment**                   Flask / FastAPI (optional)
# **âœ… Summary**
This project demonstrates a dual-model Arabic QA system combining extractive reasoning (Arabic BERT) and generative fluency (AraGPT2) to deliver contextually rich answers from real-world Arabic sports news.

