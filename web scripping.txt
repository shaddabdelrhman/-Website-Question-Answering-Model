import requests
from bs4 import BeautifulSoup
import re

headers = {"User-Agent": "Mozilla/5.0"}

def get_article_links(page_url):
    """Extract article links from a FilGoal page."""
    try:
        res = requests.get(page_url, headers=headers)
        res.raise_for_status()
        soup = BeautifulSoup(res.content, "lxml")
        links = []
        for a in soup.find_all("a", href=True):
            href = a["href"]
            if href.startswith("/articles/"):
                links.append("https://www.filgoal.com" + href)
        return list(set(links))
    except Exception as e:
        print(f"Error fetching links: {e}")
        return []

def extract_article_text(url):
    """Extract main text content from a FilGoal article."""
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.content, "lxml")
        for tag in soup(["script", "style", "noscript", "header", "footer", "aside"]):
            tag.decompose()

        tags_to_extract = ["h1", "h2", "h3", "p", "li"]
        text_segments = []
        for tag in tags_to_extract:
            for el in soup.find_all(tag):
                text = el.get_text(separator=" ", strip=True)
                if text:
                    text_segments.append(text)
        article_text = "\n".join(text_segments)
        return re.sub(r"\s+", " ", article_text).strip()
    except Exception as e:
        print(f"Failed to scrape {url}: {e}")
        return ""